{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing the Deep Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import normalize\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells import the training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "xTrain = torch.load(\"C:/Users/coliv/summerProjects/Summer-Repository/xTrain.pt\")\n",
    "xVal = torch.load(\"C:/Users/coliv/summerProjects/Summer-Repository/xVal.pt\")\n",
    "\n",
    "\n",
    "yTrain = torch.load(\"C:/Users/coliv/summerProjects/Summer-Repository/yTrain.pt\")\n",
    "yVal = torch.load(\"C:/Users/coliv/summerProjects/Summer-Repository/yVal.pt\")\n",
    "\n",
    "\n",
    "zTrain = torch.load(\"C:/Users/coliv/summerProjects/Summer-Repository/zTrain.pt\")\n",
    "zVal = torch.load(\"C:/Users/coliv/summerProjects/Summer-Repository/zVal.pt\")\n",
    "\n",
    "\n",
    "lengthsTrain = torch.load(\"C:/Users/coliv/summerProjects/Summer-Repository/lengthsTrain.pt\")\n",
    "lengthsVal = torch.load(\"C:/Users/coliv/summerProjects/Summer-Repository/lengthsVal.pt\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28000, 99, 216])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "distTrain = torch.load(\"C:/Users/coliv/summerProjects/Summer-Repository/distributionTrain.pt\")\n",
    "distVal = torch.load(\"C:/Users/coliv/summerProjects/Summer-Repository/distributionVal.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following model predicts whether a Player will switch out their Pokemon or engage in battle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BattleSequenceDataset(Dataset) :\n",
    "    def __init__(self, sequences, targets, lengths) :\n",
    "        self.sequences = sequences\n",
    "        self.targets = targets\n",
    "        self.lengths = lengths\n",
    "\n",
    "    def __len__(self) :\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx) :\n",
    "        return self.sequences[idx], self.targets[idx], self.lengths[idx]\n",
    "\n",
    "\n",
    "class ActionClassifier(nn.Module) :\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, dropout = 0.0) :\n",
    "        super(ActionClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first = True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, lengths) :\n",
    "        packed_input = pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n",
    "        packed_output, _ = self.lstm(packed_input)\n",
    "        lstm_out, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "        lstm_out = self.dropout(lstm_out)  # Apply dropout to the output of the LSTM\n",
    "        output = self.fc(lstm_out)  # Pass through the fully connected layer\n",
    "        return output    \n",
    "\n",
    "def trainModel(model, train_loader, val_loader, device, epochs=10):\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        totalLoss = 0\n",
    "        for inputs, labels, lengths in train_loader:\n",
    "            inputs = inputs.to(device)  # Ensure inputs are on GPU\n",
    "            lengths = lengths.cpu()  # Ensure lengths are on CPU\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs, lengths)  # Model expects GPU inputs and CPU lengths\n",
    "            outputsReshaped = outputs.view(-1, outputs.size(-1))\n",
    "            labelsReshaped = labels[:, :outputs.shape[1]].to(device).view(-1).long()  # Directly slice and move to GPU\n",
    "            loss = criterion(outputsReshaped, labelsReshaped)\n",
    "            totalLoss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels, lengths in val_loader:\n",
    "                inputs = inputs.to(device)  # Ensure inputs are on GPU\n",
    "                lengths = lengths.cpu()  # Ensure lengths are on CPU\n",
    "                val_outputs = model(inputs, lengths)\n",
    "                valReshaped = val_outputs.view(-1, val_outputs.size(-1))\n",
    "                valLabelsReshaped = labels[:, :val_outputs.shape[1]].to(device).view(-1).long()  # Directly slice and move to GPU\n",
    "                val_loss += criterion(valReshaped, valLabelsReshaped).item()\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{epochs}], Validation Loss: {val_loss / len(val_loader):.4f}, Training Loss: {totalLoss / len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "class ActionClassifier(nn.Module) :\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim) :\n",
    "        super(ActionClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first = True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, lengths) :\n",
    "        packed_input = pack_padded_sequence(x, lengths, batch_first = True, enforce_sorted = False)\n",
    "        packed_output, _ = self.lstm(packed_input)\n",
    "        lstm_out, _ = pad_packed_sequence(packed_output, batch_first = True)\n",
    "        output = self.fc(lstm_out)\n",
    "        return output\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "class ActionClassifier(nn.Module) :\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim) :\n",
    "        super(ActionClassifier,  self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_dim, hidden_dim, batch_first = True)\n",
    "        self.lstm2 = nn.LSTM(hidden_dim, hidden_dim, batch_first = True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, lengths) :\n",
    "        packed_input = pack_padded_sequence(x, lengths, batch_first = True, enforce_sorted = False)\n",
    "        packed_output, _ = self.lstm1(packed_input)\n",
    "        lstm_out, _ = pad_packed_sequence(packed_output, batch_first = True)\n",
    "        packed_output, _ = self.lstm2(pack_padded_sequence(lstm_out, lengths, batch_first = True, enforce_sorted = False))\n",
    "        lstm_out, _ = pad_packed_sequence(packed_output, batch_first = True)\n",
    "        output = self.fc(lstm_out)\n",
    "        return output\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m ActionClassifier(input_dim, hidden_dim, output_dim, weight_dropout)\n\u001b[0;32m     13\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 15\u001b[0m \u001b[43mtrainModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 44\u001b[0m, in \u001b[0;36mtrainModel\u001b[1;34m(model, train_loader, val_loader, device, epochs)\u001b[0m\n\u001b[0;32m     42\u001b[0m labelsReshaped \u001b[38;5;241m=\u001b[39m labels[:, :outputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]]\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mlong()  \u001b[38;5;66;03m# Directly slice and move to GPU\u001b[39;00m\n\u001b[0;32m     43\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputsReshaped, labelsReshaped)\n\u001b[1;32m---> 44\u001b[0m totalLoss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     46\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_data = BattleSequenceDataset(xTrain, yTrain, lengthsTrain)\n",
    "train_loader = DataLoader(train_data, batch_size = 32, shuffle = True)\n",
    "val_data = BattleSequenceDataset(xVal, yVal, lengthsVal)\n",
    "val_loader = DataLoader(val_data, batch_size = 32)\n",
    "\n",
    "input_dim = xTrain.shape[2]\n",
    "hidden_dim = 128 # Maybe you should experiment with the sizes. Think about possible implications of rank limitation when going to a lower dimension vector space. #128\n",
    "output_dim = 2\n",
    "weight_dropout = 0.2\n",
    "model = ActionClassifier(input_dim, hidden_dim, output_dim, weight_dropout)\n",
    "model = model.to(device)\n",
    "\n",
    "trainModel(model, train_loader, val_loader, device, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 99, 216])\n",
      "torch.Size([1])\n",
      "torch.Size([1, 19, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8947368421052632"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testLoader = DataLoader(val_data, batch_size = 1)\n",
    "\n",
    "with torch.no_grad() :\n",
    "     for inputs, labels, lengths, in testLoader :\n",
    "               print(inputs.shape)\n",
    "               print(lengths.shape)\n",
    "               val_outputs = model(inputs.to(device), lengths)\n",
    "               print(val_outputs.shape)\n",
    "               outputs = val_outputs.view(-1, val_outputs.size(-1))\n",
    "               true = labels\n",
    "               break\n",
    "\n",
    "trueArray = true.view(-1, true.size(-1))\n",
    "\n",
    "\n",
    "prob_matrix = torch.softmax(outputs, 1)\n",
    "indices = np.argsort(prob_matrix.cpu().numpy(), axis = 1)\n",
    "indices = indices[:, ::-1][:, :1]\n",
    "\n",
    "results = []\n",
    "for i, j in zip(trueArray, indices) :\n",
    "    if i[0] == -1 :\n",
    "        continue\n",
    "    if int(i[0]) == j :\n",
    "        results.append(1)\n",
    "    else :\n",
    "        results.append(0)\n",
    "\n",
    "arr = np.array(results)\n",
    "\n",
    "np.mean(arr)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19, 2])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_outputs[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above model is 80.931% accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells construct a model that attempts to predict the exact move a player will select. The following cell determines the average number of classes that are possible for the model to pick from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average movepool size in gen3 is 64.39378238341969.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:/Users/coliv/summerProjects/Summer-Repository/moveset_dictionary.csv\").set_index(\"name\").T\n",
    "movePoolSizes = []\n",
    "for i in df.columns :\n",
    "    movePoolSizes.append(sum(df[i]))\n",
    "\n",
    "movePoolSizes\n",
    "\n",
    "meanMovepool = np.mean(movePoolSizes)\n",
    "\n",
    "print(f\"The average movepool size in gen3 is {meanMovepool}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BattleSequenceDataset(Dataset) :\n",
    "    def __init__(self, sequences, targets, possibility_labels, lengths, distributions) :\n",
    "        self.sequences = sequences\n",
    "        self.targets = targets\n",
    "        self.possibility_labels = possibility_labels\n",
    "        self.lengths = lengths\n",
    "        self.distributions = distributions\n",
    "\n",
    "    def __len__(self) :\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx) :\n",
    "        return self.sequences[idx], self.targets[idx], self.possibility_labels[idx], self.lengths[idx], self.distributions[idx]\n",
    "\n",
    "\n",
    "class MoveClassifier(nn.Module) :\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, dropout = 0.0) :\n",
    "        super(MoveClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first = True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc1 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.fc2 = nn.Linear(output_dim, output_dim) # You added an fc2\n",
    "\n",
    "    def forward(self, x, lengths) :\n",
    "        packed_input = pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n",
    "        packed_output, _ = self.lstm(packed_input)\n",
    "        lstm_out, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "        currStep = self.dropout(self.fc1(lstm_out)) \n",
    "        currStep = torch.relu(currStep) # This step is new\n",
    "        output = self.fc2(currStep) # This step is new\n",
    "        return output  \n",
    "    \n",
    "def trainModel(model, train_loader, val_loader, device, epochs=10):\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        totalLoss = 0\n",
    "        for inputs, labels, possibilities, lengths, dists in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            lengths = lengths.cpu()  # Ensure lengths are on CPU\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs, lengths)  # Model expects GPU inputs and CPU lengths\n",
    "            outputsReshaped = outputs.view(-1, outputs.size(-1))\n",
    "            \n",
    "            possibilitiesReshaped = possibilities[:, :outputs.shape[1], :].to(device).view(-1, outputs.size(-1))\n",
    "            distsReshaped = dists[:, :outputs.shape[1], :].to(device).view(-1, outputs.size(-1))\n",
    "            labelsReshaped = labels[:, :outputs.shape[1]].to(device).view(-1).long()  # Directly slice and move to GPU\n",
    "            distsReshaped = distsReshaped \n",
    "            outputsReshaped = torch.mul(outputsReshaped, possibilitiesReshaped)\n",
    "            #outputsReshaped = outputsReshaped + distsReshaped\n",
    "            loss = criterion(outputsReshaped, labelsReshaped)\n",
    "            totalLoss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels, possibilities, lengths, dists in val_loader:\n",
    "                inputs = inputs.to(device)  # Ensure inputs are on GPU\n",
    "                lengths = lengths.cpu()  # Ensure lengths are on CPU\n",
    "                val_outputs = model(inputs, lengths)\n",
    "                valReshaped = val_outputs.view(-1, val_outputs.size(-1))\n",
    "                valPossibilitiesReshaped = possibilities[:, :val_outputs.shape[1], :].to(device).view(-1, outputs.size(-1))\n",
    "                valLabelsReshaped = labels[:, :val_outputs.shape[1]].to(device).view(-1).long()  # Directly slice and move to GPU\n",
    "                distsReshaped = dists[:, :val_outputs.shape[1], :].to(device).view(-1, outputs.size(-1))\n",
    "                distsReshaped = distsReshaped \n",
    "                valReshaped = torch.mul(valReshaped, valPossibilitiesReshaped)\n",
    "                #valReshaped = valReshaped + distsReshaped\n",
    "                val_loss += criterion(valReshaped, valLabelsReshaped).item()\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{epochs}], Validation Loss: {val_loss / len(val_loader):.4f}, Training Loss: {totalLoss / len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_data = BattleSequenceDataset(xTrain, yTrain, zTrain, lengthsTrain, distTrain)\n",
    "train_loader = DataLoader(train_data, batch_size = 32, shuffle = True)\n",
    "val_data = BattleSequenceDataset(xVal, yVal, zVal, lengthsVal, distVal)\n",
    "val_loader = DataLoader(val_data, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28000, 99, 354])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Validation Loss: 2.0181, Training Loss: 2.4100\n",
      "Epoch [2/50], Validation Loss: 1.8847, Training Loss: 2.0566\n",
      "Epoch [3/50], Validation Loss: 1.8316, Training Loss: 1.9670\n",
      "Epoch [4/50], Validation Loss: 1.7871, Training Loss: 1.9099\n",
      "Epoch [5/50], Validation Loss: 1.7848, Training Loss: 1.8697\n",
      "Epoch [6/50], Validation Loss: 1.7358, Training Loss: 1.8402\n",
      "Epoch [7/50], Validation Loss: 1.7143, Training Loss: 1.8137\n",
      "Epoch [8/50], Validation Loss: 1.7030, Training Loss: 1.7950\n",
      "Epoch [9/50], Validation Loss: 1.6925, Training Loss: 1.7776\n",
      "Epoch [10/50], Validation Loss: 1.6811, Training Loss: 1.7613\n",
      "Epoch [11/50], Validation Loss: 1.6663, Training Loss: 1.7488\n",
      "Epoch [12/50], Validation Loss: 1.6554, Training Loss: 1.7370\n",
      "Epoch [13/50], Validation Loss: 1.6568, Training Loss: 1.7278\n",
      "Epoch [14/50], Validation Loss: 1.6422, Training Loss: 1.7181\n",
      "Epoch [15/50], Validation Loss: 1.6349, Training Loss: 1.7110\n",
      "Epoch [16/50], Validation Loss: 1.6376, Training Loss: 1.7030\n",
      "Epoch [17/50], Validation Loss: 1.6319, Training Loss: 1.6962\n",
      "Epoch [18/50], Validation Loss: 1.6264, Training Loss: 1.6898\n",
      "Epoch [19/50], Validation Loss: 1.6262, Training Loss: 1.6845\n",
      "Epoch [20/50], Validation Loss: 1.6230, Training Loss: 1.6792\n",
      "Epoch [21/50], Validation Loss: 1.6233, Training Loss: 1.6740\n",
      "Epoch [22/50], Validation Loss: 1.6184, Training Loss: 1.6689\n",
      "Epoch [23/50], Validation Loss: 1.6122, Training Loss: 1.6660\n",
      "Epoch [24/50], Validation Loss: 1.6078, Training Loss: 1.6634\n",
      "Epoch [25/50], Validation Loss: 1.6033, Training Loss: 1.6581\n",
      "Epoch [26/50], Validation Loss: 1.6035, Training Loss: 1.6549\n",
      "Epoch [27/50], Validation Loss: 1.5988, Training Loss: 1.6519\n",
      "Epoch [28/50], Validation Loss: 1.5977, Training Loss: 1.6485\n",
      "Epoch [29/50], Validation Loss: 1.5982, Training Loss: 1.6455\n",
      "Epoch [30/50], Validation Loss: 1.5946, Training Loss: 1.6407\n",
      "Epoch [31/50], Validation Loss: 1.5958, Training Loss: 1.6394\n",
      "Epoch [32/50], Validation Loss: 1.5903, Training Loss: 1.6364\n",
      "Epoch [33/50], Validation Loss: 1.5957, Training Loss: 1.6359\n",
      "Epoch [34/50], Validation Loss: 1.5892, Training Loss: 1.6324\n",
      "Epoch [35/50], Validation Loss: 1.5883, Training Loss: 1.6302\n",
      "Epoch [36/50], Validation Loss: 1.5849, Training Loss: 1.6271\n",
      "Epoch [37/50], Validation Loss: 1.5890, Training Loss: 1.6245\n",
      "Epoch [38/50], Validation Loss: 1.5865, Training Loss: 1.6218\n",
      "Epoch [39/50], Validation Loss: 1.5907, Training Loss: 1.6216\n",
      "Epoch [40/50], Validation Loss: 1.5813, Training Loss: 1.6196\n",
      "Epoch [41/50], Validation Loss: 1.5854, Training Loss: 1.6176\n",
      "Epoch [42/50], Validation Loss: 1.5783, Training Loss: 1.6159\n",
      "Epoch [43/50], Validation Loss: 1.5885, Training Loss: 1.6141\n",
      "Epoch [44/50], Validation Loss: 1.5835, Training Loss: 1.6131\n",
      "Epoch [45/50], Validation Loss: 1.5837, Training Loss: 1.6109\n",
      "Epoch [46/50], Validation Loss: 1.5845, Training Loss: 1.6097\n",
      "Epoch [47/50], Validation Loss: 1.5762, Training Loss: 1.6085\n",
      "Epoch [48/50], Validation Loss: 1.5830, Training Loss: 1.6065\n",
      "Epoch [49/50], Validation Loss: 1.5835, Training Loss: 1.6059\n",
      "Epoch [50/50], Validation Loss: 1.5778, Training Loss: 1.6017\n"
     ]
    }
   ],
   "source": [
    "input_dim = xTrain.shape[2]\n",
    "hidden_dim = 128 # Maybe you should experiment with the sizes. Think about possible implications of rank limitation when going to a lower dimension vector space. #128\n",
    "output_dim = 354\n",
    "weight_dropout = 0.2\n",
    "model = MoveClassifier(input_dim, hidden_dim, output_dim, weight_dropout)\n",
    "model = model.to(device)\n",
    "\n",
    "trainModel(model, train_loader, val_loader, device, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "model = model.cpu()\n",
    "torch.save(model, \"C:/Users/coliv/summerProjects/Summer-Repository/moveClassifier.pt\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4199, 99, 354])\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(\"C:/Users/coliv/summerProjects/Summer-Repository/moveClassifier.pt\").cpu()\n",
    "val_data\n",
    "testLoader = DataLoader(val_data, batch_size = len(val_data))\n",
    "testLoader\n",
    "\n",
    "with torch.no_grad() :\n",
    "     for inputs, labels, possibilities, lengths, dists in testLoader :\n",
    "               val_outputs = model(inputs, lengths)\n",
    "               print(val_outputs.shape)\n",
    "               outputs = val_outputs.view(-1, val_outputs.size(-1))\n",
    "               possibilities = possibilities[:, :val_outputs.shape[2], :].view(-1, outputs.size(-1))\n",
    "               distributions = dists[:, :val_outputs.shape[2], :].view(-1, outputs.size(-1))\n",
    "               distributions = 0.1 * distributions\n",
    "               outputs = torch.mul(outputs, possibilities)\n",
    "               outputs = outputs + (2 * distributions)\n",
    "               true = labels\n",
    "               break\n",
    "\n",
    "trueArray = true.view(-1, true.size(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prob_matrix = torch.softmax(outputs, 1)\n",
    "indices = np.argsort(prob_matrix.cpu().numpy(), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices.shape\n",
    "indices = indices[:, ::-1][:, :3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8090160188429404"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for i, j in zip(trueArray, indices) :\n",
    "    if i[0] == -1 :\n",
    "        continue\n",
    "    if int(i[0]) in j :\n",
    "        results.append(1)\n",
    "    else :\n",
    "        results.append(0)\n",
    "\n",
    "arr = np.array(results)\n",
    "\n",
    "np.mean(arr)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "guessing: 1.4625%\n",
    "\n",
    "best accuracy: 52%\n",
    "\n",
    "When choosing top K = 1 : 52.055%\n",
    "\n",
    "When choosing top K = 2 : 70.305%\n",
    "\n",
    "When choosing top K = 3 : 80.902%\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'ActionClassifier' on <module '__main__'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:/Users/coliv/summerProjects/Summer-Repository/actionClassifier.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\coliv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:1025\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1023\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1024\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1025\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m                     \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1030\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[0;32m   1031\u001b[0m     f_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\coliv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:1446\u001b[0m, in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1444\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1445\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[1;32m-> 1446\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1448\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[0;32m   1449\u001b[0m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_log_api_usage_metadata(\n\u001b[0;32m   1450\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.load.metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserialization_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: zip_file\u001b[38;5;241m.\u001b[39mserialization_id()}\n\u001b[0;32m   1451\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\coliv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:1439\u001b[0m, in \u001b[0;36m_load.<locals>.UnpicklerWrapper.find_class\u001b[1;34m(self, mod_name, name)\u001b[0m\n\u001b[0;32m   1437\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1438\u001b[0m mod_name \u001b[38;5;241m=\u001b[39m load_module_mapping\u001b[38;5;241m.\u001b[39mget(mod_name, mod_name)\n\u001b[1;32m-> 1439\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't get attribute 'ActionClassifier' on <module '__main__'>"
     ]
    }
   ],
   "source": [
    "torch.load(\"C:/Users/coliv/summerProjects/Summer-Repository/actionClassifier.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
